{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.sparse.linalg as la\n",
    "import scipy.sparse as sp\n",
    "import scipy\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/Users/liujiaoyang/tensorflow/MGCNN/Data/Yahoo/training_test_dataset_10_NNs.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary functions:\n",
    "\n",
    "# import matlab files in python\n",
    "def load_matlab_file(path_file, name_field):\n",
    "    \"\"\"\n",
    "    load '.mat' files\n",
    "    inputs:\n",
    "        path_file, string containing the file path\n",
    "        name_field, string containig the field name (default='shape')\n",
    "    warning:\n",
    "        '.mat' files should be saved in the '-v7.3' format\n",
    "    \"\"\"\n",
    "    db = h5py.File(path_file, 'r')\n",
    "    ds = db[name_field]\n",
    "    try:\n",
    "        if 'ir' in ds.keys():\n",
    "            data = np.asarray(ds['data'])\n",
    "            ir   = np.asarray(ds['ir'])\n",
    "            jc   = np.asarray(ds['jc'])\n",
    "            out  = sp.csc_matrix((data, ir, jc)).astype(np.float32)\n",
    "    except AttributeError:\n",
    "        # Transpose in case is a dense matrix because of the row- vs column- major ordering between python and matlab\n",
    "        out = np.asarray(ds).astype(np.float32).T\n",
    "\n",
    "    db.close()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading of the required matrices\n",
    "M = load_matlab_file(path_dataset, 'M')\n",
    "Otraining = load_matlab_file(path_dataset, 'Otraining')\n",
    "Otest = load_matlab_file(path_dataset, 'Otest')\n",
    "Wcol = load_matlab_file(path_dataset, 'W_tracks') #dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num data samples: 2401\n",
      "Num train samples: 2401\n",
      "Num train+data samples: 4802\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "pos_tr_samples = np.where(Otraining)\n",
    "\n",
    "num_tr_samples = len(pos_tr_samples[0])\n",
    "list_idx = list(range(num_tr_samples))\n",
    "np.random.shuffle(list_idx)\n",
    "idx_data = list_idx[:num_tr_samples//2]\n",
    "idx_train = list_idx[num_tr_samples//2:]\n",
    "\n",
    "pos_data_samples = (pos_tr_samples[0][idx_data], pos_tr_samples[1][idx_data])\n",
    "pos_tr_samples = (pos_tr_samples[0][idx_train], pos_tr_samples[1][idx_train])\n",
    "\n",
    "Odata = np.zeros(M.shape)\n",
    "Otraining = np.zeros(M.shape)\n",
    "\n",
    "for k in range(len(pos_data_samples[0])):\n",
    "    Odata[pos_data_samples[0][k], pos_data_samples[1][k]] = 1\n",
    "    \n",
    "for k in range(len(pos_tr_samples[0])):\n",
    "    Otraining[pos_tr_samples[0][k], pos_tr_samples[1][k]] = 1\n",
    "    \n",
    "print ('Num data samples: %d' % (np.sum(Odata),))\n",
    "print ('Num train samples: %d' % (np.sum(Otraining),))\n",
    "print ('Num train+data samples: %d' % (np.sum(Odata+Otraining),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation of the normalized laplacians\n",
    "Lcol = sp.csgraph.laplacian(Wcol, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3000)\n",
      "(3000,)\n",
      "(3000, 3000)\n"
     ]
    }
   ],
   "source": [
    "#apply SVD initially for detecting the main components of our initialization\n",
    "U, s, V = np.linalg.svd(Odata*M, full_matrices=0)\n",
    "\n",
    "print (U.shape)\n",
    "print (s.shape)\n",
    "print (V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 10)\n",
      "(3000, 10)\n"
     ]
    }
   ],
   "source": [
    "rank_W_H = 10\n",
    "partial_s = s[:rank_W_H]\n",
    "partial_S_sqrt = np.diag(np.sqrt(partial_s))\n",
    "initial_W = np.dot(U[:, :rank_W_H], partial_S_sqrt)\n",
    "initial_H = np.dot(partial_S_sqrt, V[:rank_W_H, :]).T\n",
    "\n",
    "print (initial_W.shape)\n",
    "print (initial_H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training matrix\n",
      "Reconstructed training matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7ff035e92340>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAD8CAYAAADub8g7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfpklEQVR4nO2dbcwe1Znff38/EAMJVnERyLXd4kRuuwZpSbAIW6qILd3FoVVNPqQy0i7WisqrCLZJtVUFux/IF0tptcl2URckZ6GYNg11SSKsFWxC3KyilQjEEBZjvC5OQPDErr2EbONWisF+rn6Yc5Ph9v0yM/e8nDNz/aTRPfeZl3OdM+f857yPzAzHcZwhsaprAxzHcdrGhc9xnMHhwuc4zuBw4XMcZ3C48DmOMzhc+BzHGRytC5+kbZKOSjom6Z62/XccJ24kPSzplKSXc25rJT0t6dXwe1nu2L1BT45KuqWIH60Kn6Ql4I+BTwJbgNslbWnTBsdxoucRYNuY2z3AATPbDBwI/wn6sQO4OlzzQNCZmbRd4rseOGZmPzKzd4DHgO0t2+A4TsSY2XeBt8ectwN7w/5e4Lac+2NmdsbMXgOOkenMTC6ox9TCrAfezP1fBj4+fpKkXcAugCWWrruENe1Y5zgD5Of8P96xM1rkHrf86gftJ2+fK3Tu8y+dOQz8POe0x8z2zLnsSjM7AWBmJyRdEdzXA9/Lnbcc3GbStvBNitzz5syFSNgDsEZr7eO6uWm7nJSQINWplhHa/qwdWPgeP3n7HM998+8WOndp3as/N7OtC3uaUUhTxmlb+JaBjbn/G4DjLdvgpE5kwlGKlG2fgQErrDTpxUlJ60Jpbx1wKrhX0pS22/i+D2yWtEnSB8gaJfe3bIPjODVjGO/auUJbRfYDO8P+TuCJnPsOSaslbQI2A8/Nu1mrJT4zOyvpbuCbwBLwsJkdbtMGx3Gaoa4Sn6SvAjcBl0taBu4DvgDsk3Qn8AbwaQAzOyxpH/AKcBa4y2y+urZd1cXMngSebNtfx0mWCNsFxzGMczXZaGa3Tzk0sbHfzHYDu8v40brwOY5TkshFb8TK/D6FaHDhgzjeqEVtKHve+PmrlmBlRk2gybjI33sRf9p+Xgodh/P8nHTeNFs11hm5aHiK2tgQBpxz4UuMrkWvjA1lzxs/f5bolbl/FbQKRs0vi/jT9vNa5NlMu7buMESQhr3E5ziTmCe6TrIY8G4E4luU4QpfDNXbmOyog3lh6VNYnfdhmFd1k8AzYP3Mi9OycT4EoexLGA3OJRSM4QpfLOTbvWq/d+KZKmXbi1Jnh1aHZDM30sGFr2usweQSW2ZJIAM7VRHnJk6bjRMXvq5xIXDmkUAayTo3XPgc53wSyMBONbJxfC58ceBVK8dpjRUv8UWCi57TNQN5+XqJz3GcXzAA0QMwxLmEPtrowuc4Ti14VbdNBlKVOI+hhnuIJPCsDfGOzf24WTSkL3yRJ4jGSHHga2z29I0O4zcbwOxVXScGYhOZ2OxJhbpX7mkI79xwHGdQmIlz5iU+x3EGxoqX+BynRobeNphA+LPOjXTkJB1LneESeaZvnCZX8KkJ79xwypHA29zpmCZX8KmRcz6OryPaEJG6/RiS6DX9QZy+vkTq+EBTw/jMjS5pI1FEmvCSocn46/uziTx8K96r6zRCrG/8onbFaLtTC9kiBS58ThPEKhyx2uW0hiHe9SlrjjOBWEusfaFK/ErU8XE0M5IawLyQpZJel3RI0ouSDga3tZKelvRq+L0sd/69ko5JOirplkWN7wVKpyfMiZwqL5XaXkRipeAWA3VI9K+a2bVmtjX8vwc4YGabgQPhP5K2ADuAq4FtwAOS0ikbN4WXgJweYGQlviJbDDRhxXZgb9jfC9yWc3/MzM6Y2WvAMeD6Bvx3JhFDyTI/LKOPpBCuBm08x6pCWwwsaoUB35L0vKRdwe1KMzsBEH6vCO7rgTdz1y4HN6cNYihZNj2Or2tSCFdDNhpixYptMbBo58aNZnZc0hXA05L+asa5k0I88SkEEd0FcBGXLGiiEw0pCEOMJNAplH1eMp2+0oVKfGZ2PPyeAr5BVnU9KWkdQPg9FU5fBjbmLt8AHJ9y3z1mttXMtl7I6kVMdBynFbIPihfZYqCy8En6oKRLR/vArwMvA/uBneG0ncATYX8/sEPSakmbgM3Ac1X97w0ptAvVRdWwDimOJhF5aQ/CIgW2qtAWA4uUTa8EvqEsUV4A/Dcz+zNJ3wf2SboTeAP4NICZHZa0D3gFOAvcZRb5khNtkECiro2qc06HFEeTSKCqCwNZgdnMfgT88gT3nwA3T7lmN7C7qp9O4qxaghV/15VmnuhVFcb3OpvKXzqOmWorzUn6N8C/IrPsEPBbwCXAfweuAl4H/qWZ/bSqH3GUO535pFLdm2XnSPQWLb1I6cRHG1SNT7PaSpJZ58ZSoW0WktYD/xrYambXAEtk438njg+uigtfKiRQ1QHaWyEnlfiogyIi3/mLQHUOYL4AuFjSBWQlveNMHx9ciTSFb/whr1p6v3sTiaDKPdtIjPkwT/Kvqg2rGphU0+ZzybsvEpYipcv88Xnnrloqdz4ksfJN1rlReBzf5ZIO5rZd793H7MfAH5D1D5wA/o+ZfYvp44Mrkc7AmzzjDzlfhSrT3lHm3E7nQRbwY5pfs2yYFf4m2uLazJx5vxYJS1nRmXf+uC0F7q8LLsDOnp1vR8eUmJXxVm6K6/sIc/u3A5uAvwH+h6TfqMXAHGkK3yy8t7A4dYe/i97HATxDW4k/jKOZGzXwT4HXzOyvASR9HfhHhPHBZnZibHxwJdKs6jpxMgAR6oREvrmxwqpC2xzeAG6QdImysXI3A0eYPj64Ev0r8TmO0zpm8O7K4uUoM3tW0uPAC2TjfX8A7AE+xITxwVVx4XPqZVZ1d3QskQG50ZBAXGVV3XoqkGZ2H3DfmPMZpowProILX90MPVPPCvu8jphpzIvTmON8mm11vgQiCf8gZm44U4ggAUbHohlz3rUxx/m83vYits+LvwjCPxrOkgoufE7zRJAxkyaJ+KuvqtsGLnxdE0k1pdekHseJ2B/L9zSK4MJXhUQSohNI/VklYH/Wq5vOJ3Rc+KpQZ0Iscy8XXCdSahzA3AoufCnR1PJETtwk8ly9qusUp85EnUDmcCqQwHP1Xl2nHAkkascpgvfqOo4zKMzEWRe+gdCjUfe9JvU4btJ+qZal58GrusOhjsSYcoZ0ylNFxJpMIzUuPe/C5zgxEdPLpYotiXykyYXPmU3qVa+qFA13H+NnkTAlsB6fj+Nz5pPPAH3M5NNocpn/2FkkTFoFCXyC2sfx9ZGmBKqPmXwaQxL5gWEGZ2tYiLQtXPiKUleG9czvlCWB9j3wNj5nFi56Tg/xNj6nW7osUc7xW0tL1T6TOPRSciLhNxc+pzO6zCBz/K78bdguwtSE2CQiYFVJqXNjbmukpIclnZL0cs5traSnJb0afi/LHbtX0jFJRyXdknO/TtKhcOz+8Ok4p0/06ZHG1JGVgFiaZW18RbYYKNIN8wiwbcztHuCAmW0GDoT/SNoC7ACuDtc8IGm0OuGDwC5gc9jG7+mkTgIZNDp687IQ51ZWFdpiYK4VZvZd4O0x5+3A3rC/F7gt5/6YmZ0xs9eAY8D14cvna8zsGTMz4NHcNcOmNwnfKcT48+7Ry8JMhbYYqNrGd6WZnQAwsxOSrgju64Hv5c5bDm7vhv1x94lI2kVWOuQiLqloYiIkMji1Frpq44qpbS0WO2pm6HN1J4XcZrhPxMz2kH09nTVa28+UMiKRMVq10FWmT11sYhLuaVj8JuapWuE+GaqvhN9TwX0Z2Jg7bwNwPLhvmODuOM0zlOaEjsO5ggptMVBV+PYDO8P+TuCJnPsOSaslbSLrxHguVItPS7oh9ObekbvGcZolpaLIJBKY42yJdW7MrepK+ipwE3C5pGXgPuALwD5JdwJvAJ8GMLPDkvYBrwBngbvM3mvA+gxZD/HFwFNhc+oghaqQ03tSSoJzhc/Mbp9y6OYp5+8Gdk9wPwhcU8o6pxgppbiY8RfIQsTSY1sEn7nhOCOG3uO8AGYufMOiJwk3SoYQtz0K35CHswyPHiXcxikrZB63SZHS43Lhc9ojpZzhlMIQK5H02BbBhc+pnyFUUZ3zSOmJpyPRTjq46A0Pq3eurqS/JelxSX8l6YikX5m1KlRZXPjGaXv0exX/hjITwcko+ry7ThdWcCvGHwF/Zmb/EPhl4AhTVoWqggvfOG2XVqr4l1qJqusMmToJzNzIvK+nxCdpDfAJ4KHsvvaOmf0N01eFKo0Ln9M8owy5amn2eU3hwts4BqysqNBGNgvsYG7bNXa7DwN/DfxnST+Q9CeSPsjYqlDAFVTEOze6ZkgdAUNaiWZoGFB8HN9bZrZ1xvELgI8Bv2Nmz0r6Ixao1k7CS3xdMxTRW4RFS2wex61gVmwrwDKwbGbPhv+PkwnhtFWhSuPC58SPC1ca1NS5YWb/G3hT0j8ITjeTLXwybVWo0nhV13GcGqh9WfnfAb4i6QPAj4DfIiuonbcqVBVc+BzHqYcaC+Zm9iIwqR1w4qpQZXHhc5zYSaEDzMBW0uk9d+FznNiJXfTeIx3h884Np31iGVcXix3z6Gr8Y1nqnbnRKF7ia4oUqiddEUu85O2I+XmlMv4x0uibhAtfU8SaifpAEyIV8/OKWZRHlBvA3DlpVXXLVk2kYteMzpl1bhPVorL21XVe1fPnMatKNh7WMn6P7jvtmjJVwZEdi4Z91j3KhFMqb38ZW4raUQM1DmBunLRKfGVjrczk7nlv1SaeWN2Tz5uKn6LMqpKN+1XG79F9R9eMX1umKlhXmIumlXn+mYHNsX/e/YqEqQ3F8V7dBInlVeQMiyLV2FVL9bXzNVhtVkJZyIUvNlJoz2mbPsdJkXDV2bnRVDxG1GNbBBe+eTSd6cbv34RfZcPQVJir3rfKNX0WyyhRUp0bLnzzaDrztJE5u277a/q+XfvVNKmIeAImjnDhcxynHla6NqA4Lnxdk8rbvA6GFNY6SSHO+jaOT9LDkk5Jejnn9nlJP5b0YthuzR27V9IxSUcl3ZJzv07SoXDsfqmmgUVdTTuqy99JiTqmKUoxTOuqc6xjitT5QaoG40lWbIuBIgOYHwG2TXD/QzO7NmxPAkjaAuwArg7XPCBplIsfBHYBm8M26Z7l6eptWJe/kxJiTFOU6ozf0b3KZr5Yxql1RZ0dQk3GU0JzdecKn5l9F3i74P22A4+Z2Rkzew04BlwfloleY2bPmJkBj7LAF5Jao42ZEH3OsNMYYpgXIaYaQE9YZMra3ZJeClXh0Yd91wNv5s5ZDm7rw/64+0Qk7Rp9geldzixg4oLE0hvqDBtLo9egb1XdSTwIfAS4FjgBfDG4Tyry2Az3iZjZHjPbamZbL2R1RRMdpyek8EI1silrRbYIqCR8ZnbSzM6Z2QrwZeD6cGgZ2Jg7dQNwPLhvmODuOP2hzx0sRehTG98kRp94C3wKGPX47gd2SFotaRNZJ8Zz4eO/pyXdEHpz72CBLyQ5TinaEqSmSmaJCGpKVd254/gkfRW4iezr58vAfcBNkq4l0+/Xgd8GMLPDkvaRfQruLHCX2XtLT3yGrIf4YuCpsKVBSuPPUrK1LebFR+xxFrNteRIxEwoIn5ndPsH5oRnn7wZ2T3A/CFxTyrpYaHOu7qJ0mUnmhSVWgYnRpip0Hb8JRaPP3OiavmQ6KLb23CymZdyuM3QsNsyjQ/tiqsYWwYXPiYcuBt0WJQYbYieSHtsiuPA57ZBCiSlWEok7L/E5zjhFlvd30iahR+vC57SHi141Uog3b+NzHKd1YihNu/A5jtMqXYseoDSmFAOpfVe3jyQyKt/pEE8jteMlvq6J4E3tRMK06moqaSQRM8GFr3vKtM3E0I4zixjti9Em+IVdeftitLMo3rnhlKJMYo85Y8QqMDHaBOXELta4HScBE0d4G18TlGmTKXNuzCvxjkovZUit7Wpk7yy7Fw3TpOuLTPWrw+9FSWhZKi/xNUFTpbiYvsUxib6vWF2klLboQO0qc5UjqCoL79V1nGFTtwCpwWxa29cC612PT9KSpB9I+tPwf62kpyW9Gn4vm3ePWbjwxULRBNh1dcZpnyZL+rUuiVZwK8ZngSO5//cAB8xsM3Ag/K9Mf4UvFYEY2Vk0AaZWPZxEKs8mFmJu281Tk/BJ2gD8M+BPcs7bgb1hfy8LfqWxv218qQhEKnbWRR09lKn0ctZF7G27gRLDWS6XdDD3f4+Z7cn9/4/AvwMuzbldGT5hgZmdkHTFAqb2WPj6TqqZv6zNk8KZYrinkepznETxYLxlZlsnHZD0z4FTZva8pJvqMex8XPhSpS+ZZR59D2dfxvFZbb26NwL/QtKtwEXAGkn/FTgpaV0o7a0DTi3iSX/b+FLG28CcPFVEr4s0VEMbn5nda2YbzOwqYAfwP83sN8i+4LgznLaTBb/S6CW+GIn97e60S5USXwdpqOEpa18A9km6E3gD+PQiN3Ph6wspVIfK0scwQflwpRIHNZtpZn8O/HnY/wlwc1339qruItRRnahrqEIMmWNefJSNrxjCNI1Fnn3ZcKUwnKVoNTeSR+olvkWoI2MmMlRhIuMll5iFqm5i/Axmh/4LX53FKUPXmWURSg9NWQWWsNDPo6nnWPTl2HE6cuFrkxiEIwYb8sRmzwhLaBa7U54Ik9w00he+GDL4IjY0YX8McZJnJMSx2ZUKsb7IxknAxBFzOzckbZT0HUlHJB2W9NngPnW1BEn3Sjom6aikW3Lu10k6FI7dL/mAtUqktu5d1Uzbtd1NUiZsiYhenauzNE2RXt2zwO+a2S8BNwB3SdrClNUSwrEdwNXANuABSaNuqQeBXcDmsG2rMSxpUiVzJzCmqxZStbsIZcKWygsgoV7ducJnZifM7IWwf5psqZj1TF8tYTvwmJmdMbPXgGPA9WGayRoze8bMDHiUBVdY6AV9ztxOPTS5Hl+NaKXYFgOl2vgkXQV8FHiW6aslrAe+l7tsObi9G/bH3Sf5s4usZMhFXFLGxDRIpc3GiYNEOoViqcYWofCrRNKHgK8BnzOzn806dYKbzXA/39Fsj5ltNbOtF7K6qInp4KLnlCGF9JLYAOZCwifpQjLR+4qZfT04nwzVV8ZWS1gGNuYu3wAcD+4bJrg7QyGVtiqnGn0SvtDz+hBwxMy+lDs0bbWE/cAOSaslbSLrxHguVItPS7oh3PMOFlxhwUmMFEouMZLAC2M0cyOVXt0ibXw3Ar8JHJL0YnD7PaaslmBmhyXtA14h6xG+y+y94fqfAR4BLgaeCpszFPJtm97O2Tu0ks7znCt8ZvYXTG6fgymrJZjZbmD3BPeDwDVlDHQapk0BGuq83kVJIa4iqsYWIf2ZG85ipJCpnCSIpRpbBBe+rvEqX5yk/Fy6sj2h6HLh65pUM1ffSfm5zLO9IWH0El9bpPxWHiL+vOKgqWeQ0KNNW/j6kIlcDJw+YPFMRytC2sLXB4YkekMKa52sWop+pW5fgdlxnHopInox1By69r8ELnyO0wciEB0v8TmOMyx8AHPPiKEK4TgJ4J0bfcJFz3EKkZLwpbG0a1ESWMUiCRvrYjysVT+MncIHtfPkw131eU+6ru4PtteJ8YsPSs3bIqBfJb5IInUmKdhYF+NhrTokI/KhHOdRx2IM+euKfqXOv6tbmH4Jn5Me3oaaMSseUomfRMyEvgmfZ6K4mfR86npeqT/7lG3HBzB3S+KJp/c0+Xz82XeLWb8WInWc2khg6pWzAOnonguf0yJNT71Kvbo7jUTC5VXdpkgkATgLsMjz9bTRHQZ4VbchPGE7Q6RIui9aKGiy8JBQ9uzXAGbHGSrTxGx8UHODhYe6Pi8paaOk70g6IumwpM8G97WSnpb0avi9rKqt/RW+LkexD2l2RsxMew6ppY1F7G2xlqQVK7QV4Czwu2b2S8ANwF2StgD3AAfMbDNwIPyvRH+Fr8tqsZmLXwzEOCC4r801VmKbdyuzE2b2Qtg/DRwB1gPbgb3htL3AbVXNTauNLyX6msCd9kkgLWUDmAvbebmkg7n/e8xsz8T7SlcBHwWeBa40sxOQiaOkK6ra68LnOE49FF+d5S0z2zrvJEkfAr4GfM7MfqYaa1H9reo6Tl9IpNlEZoW2QveSLiQTva+Y2deD80lJ68LxdcCpqra68NVBIgnTSZQEqrp1tvEpK9o9BBwxsy/lDu0Hdob9ncATVc2dK3wzupY/L+nHkl4M2625a+6VdEzSUUm35Nyvk3QoHLtfdZZduySFhOk4jVKsR7dgr+6NwG8C/2RMX74A/JqkV4FfC/8rUaSNb9S1/IKkS4HnJT0djv2hmf1B/uTQ7bwDuBr4O8C3Jf19MzsHPAjsAr4HPAlsA56qarzjJElfZyDVFCYz+wuy/pJJ3FyHH3NLfDO6lqexHXjMzM6Y2WvAMeD6UCdfY2bPmJkBj7JAd7TjJEtZgShSMeq68hQ+KF5ki4FSbXxjXcsAd0t6SdLDuVHU64E3c5ctB7f1YX/c3RkKXWfOVCkilDGUIBNaer6w8I13LZNVWz8CXAucAL44OnXC5TbDfZJfuyQdlHTwXc4UNdGJnUgSvdMQNXVutEGhcXyTupbN7GTu+JeBPw1/l4GNucs3AMeD+4YJ7ucRBjPuAVijtZFEVUP0tb0nJWJ/BrPsi8h2rURSjy1AkV7diV3Lo/E0gU8BL4f9/cAOSaslbQI2A8+FEdenJd0Q7nkHC3RH94ZIEm0r1FXVrbvKHPszmGVfLLYb2QDmIlsEFCnxjbqWD0l6Mbj9HnC7pGvJgvw68NsAZnZY0j7gFbIe4btCjy7AZ4BHgIvJenO9R9cpTyyZ3XkPUXxwcgzMFb4ZXctPzrhmN7B7gvtB4JoyBvaaiKopTsSkkk5SsDHgc3W7ZFJCSSWRVyGGcNUZv209qxjirQip2IkL3+IsmvjHr08o8ZzHvI8J1SUUi9ynzvjtOiwxMWrjS4T+CV/bCWlRv/qQ6EfM+5jQKKyLPqM+xVnXy8XXSEq9uv0TvgQSyPtIJFHXSpWZC6lVTwdHPIOTi9A/4XPOJ5bMXtWOWJsS2opXrQKL/HvERhxprCAufF0zpMbxWOyoi7bC00a7aR2kU9N14XN6Tiyi0BQRha9X4/gcx3EK4cLnNEZMVZuY8XhqFzM4l05d14Wva8pmUM/MxYglnoYkwAmF04WvaxJKLE4FYn++Un1LRcUe1hwufI4zZOoSKwOKfU8jClz4umZIVSHnfEZLbLWVBhpLbwbmbXzDIJ+IXMDmM28u7xBpO8005Z/hnRuDoY4ZAX0RSxf+5kglblOwMeDC59RDkUTvpb1+48LnREMqpYUY8LhaAF+kYHjEnGFisivmeIK4bYsdA3xZqoFR5+ohfWYo4aybVOItFTtx4euehBKL0xFJvBx9yprTFF1ngCL+d21jH5kVn7HEt4H5OD6nEbpO4EX8n3XOaBxfH8bzxbIqdNdpIo/P3HCcGaQuehDfR4tiIKFwuPA59VCk1FJW8GKpxnVNCvFg5r26zgBpImPGntmd95PQ83LhcxynBgw7l04Thguf48ROCiUpX5bKcZxBktBwllVdG+A4zhxGa/ZFjAG2YoW2eUjaJumopGOS7mnCXhc+x3EWx8JCpEW2GUhaAv4Y+CSwBbhd0pa6zfWqrtM+KQzPcEpTU+fG9cAxM/sRgKTHgO3AK3XcfET0wnean/7fb9vjR7u2I8flwFtdG5EjPXva17z04ihP8/H19xa9wWl++s1v2+OXFzz9IkkHc//3mNmesL8eeDN3bBn4+KL2jRO98AFHzWxr10aMkHTQ7ZlObPZAfDbFZk8dmNm2mm41qUGzdun3Nj7HcWJiGdiY+78BOF63Jy58juPExPeBzZI2SfoAsAPYX7cnKVR198w/pVXcntnEZg/EZ1Ns9kSDmZ2VdDfwTWAJeNjMDtftj8x71xzHGRhe1XUcZ3C48DmOMziiFb42pq1M8fd1SYckvTgaayRpraSnJb0afi/LnX9vsPGopFtqsuFhSackvZxzK22DpOtCWI5Jul+qNvdpij2fl/TjEE8vSrq1RXs2SvqOpCOSDkv6bHDvJI5m2NNZHDlzMLPoNrJGzR8CHwY+APwlsKUlv18HLh9z+w/APWH/HuDfh/0twbbVwKZg81INNnwC+Bjw8iI2AM8Bv0I2Nuop4JM12vN54N9OOLcNe9YBHwv7lwL/K/jbSRzNsKezOPJt9hZrie+9aStm9g4wmrbSFduBvWF/L3Bbzv0xMztjZq8Bx8hsXwgz+y7w9iI2SFoHrDGzZyzLUY/mrqnDnmm0Yc8JM3sh7J8GjpCN+O8kjmbYM43G48iZTazCN2nayqyEVCcGfEvS85J2BbcrzewEZIkcuKIDO8vasD7sN2nb3ZJeClXhUbWyVXskXQV8FHiWCOJozB6III6c84lV+FqZtjKFG83sY2SrQ9wl6RMzzu3Sznk2NG3bg8BHgGuBE8AX27ZH0oeArwGfM7OfzTq1DZsm2NN5HDmTiVX4Wpm2MgkzOx5+TwHfIKu6ngzVEMLvqQ7sLGvDcthvxDYzO2lm5yz7mOqX+UUVvxV7JF1IJjJfMbOvB+fO4miSPV3HkTOdWIWvlWkr40j6oKRLR/vArwMvB793htN2Ak+E/f3ADkmrJW0CNpM1TjdBKRtCVe+0pBtCz+AduWsWZiQwgU+RxVMr9oTrHwKOmNmXcoc6iaNp9nQZR84cuu5dmbYBt5L1jv0Q+P2W/PwwWW/bXwKHR/4Cfxs4ALwaftfmrvn9YONRauqBA75KVjV6l6wUcGcVG4CtZJnth8B/IszUqcme/wIcAl4iy8jrWrTnH5NVAV8CXgzbrV3F0Qx7Oosj32ZvPmXNcZzBEWtV13EcpzFc+BzHGRwufI7jDA4XPsdxBocLn+M4g8OFz3GcweHC5zjO4Pj/cGq4pnlFM8sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print ('Original training matrix')\n",
    "plt.figure()\n",
    "plt.imshow(Odata*M)\n",
    "plt.colorbar()\n",
    "\n",
    "print ('Reconstructed training matrix')\n",
    "plt.figure()\n",
    "plt.imshow(np.dot(initial_W, initial_H.T))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_test_matrix_completion:\n",
    "    \n",
    "    \"\"\"\n",
    "    The neural network model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def frobenius_norm(self, tensor):\n",
    "        square_tensor = tf.square(tensor)\n",
    "        tensor_sum = tf.reduce_sum(square_tensor)\n",
    "        frobenius_norm = tf.sqrt(tensor_sum)\n",
    "        return frobenius_norm\n",
    "    \n",
    "    def mono_conv(self, list_lap, ord_conv, A, W, b):\n",
    "        \n",
    "        feat = []\n",
    "        #collect features\n",
    "        for k in range(ord_conv):\n",
    "            c_lap = list_lap[k] \n",
    "                                                     \n",
    "            #dense implementation\n",
    "            c_feat = tf.matmul(c_lap, A, a_is_sparse=False)\n",
    "            feat.append(c_feat)\n",
    "            \n",
    "        all_feat = tf.concat(feat, 1)\n",
    "        conv_feat = tf.matmul(all_feat, W) + b\n",
    "        conv_feat = tf.nn.relu(conv_feat)\n",
    "        \n",
    "        return conv_feat\n",
    "    \n",
    "    def compute_cheb_polynomials(self, L, ord_cheb, list_cheb):\n",
    "        for k in range(ord_cheb):\n",
    "            if (k==0):\n",
    "                list_cheb.append(tf.cast(tf.diag(tf.ones([tf.shape(L)[0],])), 'float32'))\n",
    "            elif (k==1):\n",
    "                list_cheb.append(tf.cast(L, 'float32'))\n",
    "            else:\n",
    "                list_cheb.append(2*tf.matmul(L, list_cheb[k-1])  - list_cheb[k-2])  \n",
    "    \n",
    "    def __init__(self, M, Lc, Odata, Otraining, Otest, initial_W, initial_H,\n",
    "                 order_chebyshev_col = 5,\n",
    "                 num_iterations = 10, gamma=1.0, gamma_W=1.0, learning_rate=1e-4, idx_gpu = '/gpu:1'):\n",
    "        \n",
    "        #order of the spectral filters\n",
    "        self.ord_col = order_chebyshev_col\n",
    "        self.num_iterations = num_iterations\n",
    "        self.n_conv_feat = 32\n",
    "        \n",
    "        with tf.Graph().as_default() as g:\n",
    "                tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "                self.graph = g\n",
    "                tf.set_random_seed(0)\n",
    "                with tf.device(idx_gpu):\n",
    "                    \n",
    "                        #loading of the laplacians\n",
    "                        self.Lc = tf.cast(Lc, 'float32')\n",
    "                        \n",
    "                        self.norm_Lc = self.Lc - tf.diag(tf.ones([Lc.shape[0], ]))\n",
    "                        \n",
    "                        #compute all chebyshev polynomials a priori\n",
    "                        self.list_col_cheb_pol = list()\n",
    "                        self.compute_cheb_polynomials(self.norm_Lc, self.ord_col, self.list_col_cheb_pol)\n",
    "                        \n",
    "                        #definition of constant matrices\n",
    "                        self.M = tf.constant(M, dtype=tf.float32)\n",
    "                        self.Odata = tf.constant(Odata, dtype=tf.float32)\n",
    "                        self.Otraining = tf.constant(Otraining, dtype=tf.float32) #training mask\n",
    "                        self.Otest = tf.constant(Otest, dtype=tf.float32) #test mask\n",
    "                         \n",
    "                        ##################################definition of the NN variables#####################################\n",
    "                        \n",
    "                        #definition of the weights for extracting the global features\n",
    "                        self.W_conv_H = tf.get_variable(\"W_conv_H\", shape=[self.ord_col*initial_W.shape[1], self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.b_conv_H = tf.Variable(tf.zeros([self.n_conv_feat,]))\n",
    "                        \n",
    "                        #recurrent N parameters\n",
    "                        self.W_f_t = tf.get_variable(\"W_f_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.W_i_t = tf.get_variable(\"W_i_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.W_o_t = tf.get_variable(\"W_o_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.W_c_t = tf.get_variable(\"W_c_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.U_f_t = tf.get_variable(\"U_f_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.U_i_t = tf.get_variable(\"U_i_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.U_o_t = tf.get_variable(\"U_o_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.U_c_t = tf.get_variable(\"U_c_t\", shape=[self.n_conv_feat, self.n_conv_feat], initializer=tf.glorot_uniform_initializer())\n",
    "                        self.b_f_t = tf.Variable(tf.zeros([self.n_conv_feat,]))\n",
    "                        self.b_i_t = tf.Variable(tf.zeros([self.n_conv_feat,]))\n",
    "                        self.b_o_t = tf.Variable(tf.zeros([self.n_conv_feat,]))\n",
    "                        self.b_c_t = tf.Variable(tf.zeros([self.n_conv_feat,]))\n",
    "                        \n",
    "                        #output parameters\n",
    "                        self.W_out_H = tf.get_variable(\"W_out_H\", shape=[self.n_conv_feat, initial_H.shape[1]], initializer=tf.glorot_uniform_initializer()) \n",
    "                        self.b_out_H = tf.Variable(tf.zeros([initial_H.shape[1],]))\n",
    "                        \n",
    "                        #########definition of the NN\n",
    "                        #definition of W and H\n",
    "                        self.W = tf.Variable(initial_W.astype('float32'))\n",
    "                        self.H = tf.constant(initial_H.astype('float32'))\n",
    "                        \n",
    "                        self.X = tf.matmul(self.W, self.H, transpose_b=True) #we may initialize it at random here\n",
    "                        self.list_X = list()\n",
    "                        self.list_X.append(tf.identity(self.X))\n",
    "                        \n",
    "                        #RNN\n",
    "                        self.h_t = tf.zeros([M.shape[0], self.n_conv_feat])\n",
    "                        self.c_t = tf.zeros([M.shape[0], self.n_conv_feat])\n",
    "                        \n",
    "                        \n",
    "                        for k in range(self.num_iterations):\n",
    "                            #extraction of global features vectors\n",
    "                            self.final_feat_tracks = self.mono_conv(self.list_col_cheb_pol, self.ord_col, self.H, self.W_conv_H, self.b_conv_H)\n",
    "                            \n",
    "                            #here we have to split the features between users and movies LSTMs\n",
    "                            \n",
    "                            #users RNN\n",
    "                            self.f_t = tf.sigmoid(tf.matmul(self.final_feat_tracks, self.W_f_t) + tf.matmul(self.h_t, self.U_f_t) + self.b_f_t)\n",
    "                            self.i_t = tf.sigmoid(tf.matmul(self.final_feat_tracks, self.W_i_t) + tf.matmul(self.h_t, self.U_i_t) + self.b_i_t)\n",
    "                            self.o_t = tf.sigmoid(tf.matmul(self.final_feat_tracks, self.W_o_t) + tf.matmul(self.h_t, self.U_o_t) + self.b_o_t)\n",
    "                            \n",
    "                            self.update_c_t = tf.sigmoid(tf.matmul(self.final_feat_tracks, self.W_c_t) + tf.matmul(self.h_t, self.U_c_t) + self.b_c_t)\n",
    "                            self.c_t = tf.multiply(self.f_t, self.c_t) + tf.multiply(self.i_t, self.update_c_t)\n",
    "                            self.h_t = tf.multiply(self.o_t, tf.sigmoid(self.c_t))\n",
    "                            \n",
    "                            #compute update of matrix X\n",
    "                            self.delta_H = tf.tanh(tf.matmul(self.c_t, self.W_out_H) + self.b_out_H) #N x rank_W_H\n",
    "                            \n",
    "                            self.H += self.delta_H\n",
    "                        \n",
    "                            self.X = tf.matmul(self.W, self.H, transpose_b=True)\n",
    "                            self.list_X.append(tf.identity(tf.reshape(self.X, [tf.shape(self.M)[0], tf.shape(self.M)[1]])))\n",
    "                        self.X = tf.matmul(self.W, self.H, transpose_b=True)\n",
    "                        #########loss definition\n",
    "                        \n",
    "                        #computation of the accuracy term\n",
    "                        self.norm_X = 1+99*(self.X-tf.reduce_min(self.X))/(tf.reduce_max(self.X-tf.reduce_min(self.X)))\n",
    "                        frob_tensor = tf.multiply(self.Otraining + self.Odata, self.norm_X - M)\n",
    "                        self.loss_frob = tf.square(self.frobenius_norm(frob_tensor))/np.sum(Otraining+Odata)\n",
    "                        \n",
    "                        #computation of the regularization terms\n",
    "                        trace_col_tensor = tf.matmul(tf.matmul(self.X, self.Lc), self.X, transpose_b=True)\n",
    "                        self.loss_trace_col = tf.trace(trace_col_tensor)/tf.cast(tf.shape(self.X)[0]*tf.shape(self.X)[1],'float32')\n",
    "                        \n",
    "                        self.frob_norm_W = tf.square(self.frobenius_norm(self.W))/tf.cast(tf.shape(self.W)[0]*tf.shape(self.W)[1], 'float32')\n",
    "                        \n",
    "                        \n",
    "                        #training loss definition\n",
    "                        self.loss = self.loss_frob + (gamma/2)*self.loss_trace_col + (gamma_W/2)*self.frob_norm_W\n",
    "                        \n",
    "                        #test loss definition\n",
    "                        self.predictions = tf.multiply(self.Otest, self.norm_X - self.M)\n",
    "                        self.predictions_error = self.frobenius_norm(self.predictions)\n",
    "\n",
    "                        #definition of the solver\n",
    "                        self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)\n",
    "                        \n",
    "                        self.var_grad = tf.gradients(self.loss, tf.trainable_variables())\n",
    "                        self.norm_grad = self.frobenius_norm(tf.concat([tf.reshape(g, [-1]) for g in self.var_grad], 0))\n",
    "\n",
    "                        # Create a session for running Ops on the Graph.\n",
    "                        config = tf.ConfigProto(allow_soft_placement = True)\n",
    "                        config.gpu_options.allow_growth = True\n",
    "                        self.session = tf.Session(config=config)\n",
    "\n",
    "                        # Run the Op to initialize the variables.\n",
    "                        init = tf.initialize_all_variables()\n",
    "                        self.session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_col = 5\n",
    "n_test_samples = np.sum(Otest)\n",
    "\n",
    "learning_obj = Train_test_matrix_completion(M, Lcol, Odata, Otraining, Otest, \n",
    "                                                    initial_W, initial_H,\n",
    "                                                    order_chebyshev_col = ord_col, \n",
    "                                                    gamma=1e2, gamma_W=1e-2,\n",
    "                                                    learning_rate=1e-3)\n",
    "\n",
    "num_iter_test = 100\n",
    "num_total_iter_training = 10000\n",
    "\n",
    "list_training_loss = list()\n",
    "list_training_norm_grad = list()\n",
    "list_test_pred_error = list()\n",
    "list_predictions = list()\n",
    "list_X = list()\n",
    "\n",
    "list_training_times = list()\n",
    "list_test_times = list()\n",
    "list_grad_X = list()\n",
    "list_RMSE = []\n",
    "\n",
    "list_X_evolutions = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRN] iter = 000, cost = 3.41e+03, |grad| = 9.80e+03 (1.06e+01s)\n",
      "[TST] iter = 000, cost = 893.415649, RMSE = 38.698128 (5.45s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f06832936e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     _, current_training_loss, norm_grad, X_grad = learning_obj.session.run([learning_obj.optimizer, learning_obj.loss, \n\u001b[0m\u001b[1;32m      6\u001b[0m                                                                                         learning_obj.norm_grad, learning_obj.var_grad]) \n\u001b[1;32m      7\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iter = 0\n",
    "for k in range(num_iter, num_total_iter_training):\n",
    "\n",
    "    tic = time.time()\n",
    "    _, current_training_loss, norm_grad, X_grad = learning_obj.session.run([learning_obj.optimizer, learning_obj.loss, \n",
    "                                                                                        learning_obj.norm_grad, learning_obj.var_grad]) \n",
    "    training_time = time.time() - tic\n",
    "\n",
    "    list_training_loss.append(current_training_loss)\n",
    "    list_training_norm_grad.append(norm_grad)\n",
    "    list_training_times.append(training_time)\n",
    "    \n",
    "    if (np.mod(num_iter, num_iter_test)==0):\n",
    "        msg = \"[TRN] iter = %03i, cost = %3.2e, |grad| = %.2e (%3.2es)\" \\\n",
    "                                    % (num_iter, list_training_loss[-1], list_training_norm_grad[-1], training_time)\n",
    "        print (msg)\n",
    "                    \n",
    "        #Test Code\n",
    "        tic = time.time()\n",
    "        pred_error, preds, X = learning_obj.session.run([learning_obj.predictions_error, learning_obj.predictions,\n",
    "                                                                             learning_obj.norm_X]) \n",
    "                    \n",
    "        test_time = time.time() - tic\n",
    "\n",
    "        list_test_pred_error.append(pred_error)\n",
    "        list_test_times.append(test_time)\n",
    "        RMSE = np.sqrt(np.square(pred_error)/n_test_samples)\n",
    "        list_RMSE.append(RMSE)\n",
    "        msg =  \"[TST] iter = %03i, cost = %f, RMSE = %f (%03.2fs)\" % (num_iter, list_test_pred_error[-1], RMSE, test_time)\n",
    "        print (msg)\n",
    "\n",
    "    num_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(np.arange(len(list_training_loss)), list_training_loss, 'g-')\n",
    "ax2.plot(np.arange(len(list_test_pred_error))*num_iter_test, list_test_pred_error, 'b-')\n",
    "\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Training loss', color='g')\n",
    "ax2.set_ylabel('Test loss', color='b')\n",
    "\n",
    "best_iter = (np.where(np.asarray(list_training_loss)==np.min(list_training_loss))[0][0]//num_iter_test)*num_iter_test\n",
    "best_pred_error = list_test_pred_error[best_iter//num_iter_test]\n",
    "print ('Best predictions at iter: %d (error: %f)' % (best_iter, best_pred_error))\n",
    "RMSE = np.sqrt(np.square(best_pred_error)/np.sum(Otest))\n",
    "print ('RMSE: %f' % RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last X generated\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(X)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
